{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqbFmKvxoroF"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## <center> GROUP PROJECT - TO GRANT OR NOT TO GRANT: DECIDING ON COMPENSATION BENEFITS </center> <br>\n",
    "#  <center> <b> K Nearest Neighbors Classifier </center> <br>\n",
    "## <center> Fall Semester 2024-2025 <center>\n",
    "<br>\n",
    "<center> Group 46: <center> <br>\n",
    "<center>Afonso Ascensão, 20240684 <br><center>\n",
    "<center>Duarte Marques, 20240522 <br><center>\n",
    "<center>Joana Esteves, 20240746 <br><center>\n",
    "<center>Rita Serra, 20240515 <br><center>\n",
    "<center>Rodrigo Luís, 20240742 <br><center>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of contents:**\n",
    "- Apply pipeline to preprocess the data.\n",
    "- Implement K Nearest Neighbors algorithm, perform tuning of hyperparameters making use of gridsearch.\n",
    "- Assessement of the model using cross validation.\n",
    "- Generate prediction for the test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMXFdXdzoroI"
   },
   "source": [
    "**Table of Contents**\n",
    "- [1. Import the needed Libraries](#importlibraries)\n",
    "- [2. Import Dataset](#importdataset)\n",
    "- [3. Preprocessing](#section_3)\n",
    "- [4. kNN Classifier](#section_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL9oVLaT6fER"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_1\">\n",
    "\n",
    "# 1. Import Libraries\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69HiGJ-s8roW",
    "outputId": "80b74294-f5eb-4daa-d490-0fc7f7897f8b"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "## Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import load\n",
    "from transformers import *\n",
    "## Target Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Model algorithm - kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "\n",
    "# Cross validation, parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define a seed\n",
    "random_state = 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVnubShx6mP0"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_2\">\n",
    "\n",
    "# 2. Import Dataset and Pipeline\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation w/ split, separate X and y to apply preprocessing\n",
    "transformed_train_split = pd.read_parquet(\"transformed_train_split.parquet\")\n",
    "transformed_val_split = pd.read_parquet(\"transformed_val_split.parquet\")\n",
    "\n",
    "# Test set with predicted agreement column, apply preprocessing \n",
    "test_transformed_agreement = pd.read_parquet(\"test_transformed_agreement.parquet\")\n",
    "\n",
    "# Dataset with no split for cross validation, apply pipeline inside cross validation\n",
    "transformed_train_data = pd.read_parquet(\"transformed_train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline\n",
    "pipeline = load('pipeline.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section_3\">\n",
    "\n",
    "# 3. Preprocessing\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y for train after split\n",
    "X_train = transformed_train_split.drop(['Claim Injury Type'], axis = 1)\n",
    "y_train = transformed_train_split['Claim Injury Type']\n",
    "\n",
    "# Separate X and y for validation after split\n",
    "X_val = transformed_val_split.drop(['Claim Injury Type'], axis = 1)\n",
    "y_val = transformed_val_split['Claim Injury Type']\n",
    "\n",
    "# Separate X and y for dataset before split\n",
    "X = transformed_train_data.drop(['Claim Injury Type'], axis = 1)\n",
    "y = transformed_train_data['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encoding of y for train and validation sets\n",
    "\n",
    "# Initialize target encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode target\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the train, validation and test sets\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train, y_train_encoded)\n",
    "X_val_preprocessed = pipeline.transform(X_val)\n",
    "test_data_preprocessed = pipeline.transform(test_transformed_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Attorney/Representative' 'Average Weekly Wage Log' 'C-2 Delivered'\n",
      " 'Industry Code' 'Time Assembly to Hearing' 'Hearing Held'\n",
      " 'Agreement Reached' 'C-3 Delivered on Time' 'Part of Body Group_Trunk'\n",
      " 'Part of Body Group_Lower Extremities' 'IME-4 Count Log'\n",
      " 'District Name_NYC' 'Part of Body Group_Upper Extremities' 'Gender'\n",
      " 'Carrier Type_2A. SIF' 'Cause of Injury Group_X' 'Assembly Year'\n",
      " 'Cause of Injury Group_VI']\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected features:\", X_train_preprocessed.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section_4\">\n",
    "\n",
    "# 4. kNN Classifier\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables for model:**\n",
    "- X_train_preprocessed;\n",
    "- y_train_preprocessed;\n",
    "- X_val_preprocessed;\n",
    "- y_val_encoded;\n",
    "- test_data_preprocessed.\n",
    "\n",
    "**Variables for CV:**\n",
    "- X: no preprocessing and no split;\n",
    "- y: no preprocessing and no split;\n",
    "- Apply pipeline inside cv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__n_neighbors': 10, 'model__weights': 'uniform'}\n",
      "Best score: 0.3278968095380786\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# Append the model to the imported pipeline\n",
    "full_pipeline = Pipeline(\n",
    "    pipeline.steps + [('model', KNeighborsClassifier(algorithm=\"kd_tree\"))]\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [10, 13, 15],\n",
    "    'model__weights':[\"distance\", \"uniform\"]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X, y_encoded)\n",
    "\n",
    "# Display best parameters and best cv score \n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model with selected hyperparameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duama\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\duama\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\duama\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\duama\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.42      0.51     11229\n",
      "           1       0.80      0.96      0.87    261970\n",
      "           2       0.46      0.15      0.23     62016\n",
      "           3       0.75      0.75      0.75    133656\n",
      "           4       0.67      0.61      0.64     43452\n",
      "           5       0.51      0.02      0.05      3790\n",
      "           6       0.00      0.00      0.00        87\n",
      "           7       0.58      0.15      0.24       423\n",
      "\n",
      "    accuracy                           0.76    516623\n",
      "   macro avg       0.55      0.38      0.41    516623\n",
      "weighted avg       0.73      0.76      0.73    516623\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.41      0.49      1248\n",
      "           1       0.78      0.95      0.86     29108\n",
      "           2       0.29      0.09      0.14      6890\n",
      "           3       0.70      0.69      0.70     14851\n",
      "           4       0.59      0.55      0.57      4828\n",
      "           5       0.17      0.00      0.01       421\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.56      0.11      0.18        47\n",
      "\n",
      "    accuracy                           0.72     57403\n",
      "   macro avg       0.46      0.35      0.37     57403\n",
      "weighted avg       0.68      0.72      0.69     57403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duama\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\duama\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=10,\n",
    "    algorithm=\"kd_tree\", \n",
    "    weights=\"uniform\"\n",
    ")\n",
    "\n",
    "knn.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_train = knn.predict(X_train_preprocessed)\n",
    "y_pred_val = knn.predict(X_val_preprocessed)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The scores are similar for train and validation.\n",
    "- The model is not predicting class 6 and 7, most likely because it does not have enough observations.\n",
    "- The minority classes have a very low f1 score.\n",
    "- The f1 macro scores are low for both train and validation which indicate the model may be underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation w/ 5 splits for final assessement of the model with selected hyperparameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (F1-macro): [0.36470054 0.36521196 0.35786806]\n",
      "Mean CV score: 0.36259351931565237\n"
     ]
    }
   ],
   "source": [
    "# Append the model to the imported pipeline\n",
    "full_pipeline = Pipeline(\n",
    "    pipeline.steps + [('model', knn)]\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Use F1-macro because of class imbalance\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Get scores for cross-validation\n",
    "# Apply preprocessing inside cv for X and y_encoded\n",
    "cv_scores = cross_val_score(full_pipeline, X, y_encoded, cv=cv, scoring=scorer)\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-validation scores (F1-macro):\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean CV f1 macro: 0.3625935193156523\n",
    "- This value will be compared with the other models mean cv scores to select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions for test set using all incial train data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Fit pipeline on X and apply tranformations\n",
    "X_preprocessed = pipeline.fit_transform(X, y_encoded)\n",
    "\n",
    "# Apply pipeline fitted on X\n",
    "test_data_preprocessed_X = pipeline.transform(test_transformed_agreement)\n",
    "\n",
    "# Fit on X \n",
    "knn.fit(X_preprocessed,y_encoded)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = knn.predict(test_data_preprocessed_X)\n",
    "\n",
    "# Get original y for submission\n",
    "y_pred_categorical = label_encoder.inverse_transform(y_pred) \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Claim Identifier\": test_data_preprocessed.index,\n",
    "    \"Claim Injury Type\": y_pred_categorical\n",
    "})\n",
    "\n",
    "\n",
    "# Save to CSV to upload on kaggle\n",
    "submission.to_csv(\"Group46_versionX.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kaggle f1 macro score from test: 0.32389."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MqbFmKvxoroF",
    "BL9oVLaT6fER",
    "WVnubShx6mP0",
    "Al0mdDUBoroL",
    "6JjINtuHoroN",
    "akZH_ydMoroO",
    "hcJOdUk1K1kz",
    "6bzFiE2BoroR",
    "XAVSrcx5oroU",
    "TpNi7Q5ioroU",
    "c3wplzqvoroU",
    "wBA2IAMcoroV",
    "FFzpmY9KQPDs",
    "QILO2RwcAxwV",
    "qJDNJDf4BUYd",
    "HMW-CmnSoroX",
    "kkH3JUYYE4VW",
    "ADZcJgYioroX",
    "nZeA99aHGzTQ",
    "z9PEn_R5NjdK"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
