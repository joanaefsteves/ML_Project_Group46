{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqbFmKvxoroF"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## <center> GROUP PROJECT - TO GRANT OR NOT TO GRANT: DECIDING ON COMPENSATION BENEFITS </center> <br>\n",
    "#  <center> <b> Agreement Reached Model </center> <br>\n",
    "## <center> Fall Semester 2024-2025 <center>\n",
    "<br>\n",
    "<center> Group 46: <center> <br>\n",
    "<center>Afonso Ascensão, 20240684 <br><center>\n",
    "<center>Duarte Marques, 20240522 <br><center>\n",
    "<center>Joana Esteves, 20240746 <br><center>\n",
    "<center>Rita Serra, 20240515 <br><center>\n",
    "<center>Rodrigo Luís, 20240742 <br><center>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of contents:**\n",
    "This notebook aims to develop a model to predict the binary variable \"Agreement Reached\" that is present in the train data for our main model (target \"Claim Injury Type\") but it was not part of the test dataset. The final selected model from this notebook makes predictions for the target \"Agreement Reached\" to join our test dataset, in order for us to be able to include it as a feature for our main model.\n",
    "- Apply pipeline to preprocess the data.\n",
    "- Implement xgboost algorithm, perform tuning of hyperparameters making use of gridsearch.\n",
    "- Test KNN algorithm and oversampling with SMOTE.\n",
    "- Generate predictions of the target variable \"Agreement Reached\" for the test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMXFdXdzoroI"
   },
   "source": [
    "**Table of Contents**\n",
    "- [1. Import the needed Libraries](#importlibraries)\n",
    "- [2. Import Dataset](#importdataset)\n",
    "- [3. Split and Pipeline](#section_3)\n",
    "- [4. Models](#section_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL9oVLaT6fER"
   },
   "source": [
    "<a class=\"anchor\" id=\"importlibraries\">\n",
    "\n",
    "# 1. Import the needed Libraries\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69HiGJ-s8roW",
    "outputId": "80b74294-f5eb-4daa-d490-0fc7f7897f8b"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocessing\n",
    "## Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import load\n",
    "from transformers import *\n",
    "## Target Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Model Algorithm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Data Split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "# Define a seed\n",
    "random_state = 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVnubShx6mP0"
   },
   "source": [
    "<a class=\"anchor\" id=\"importdataset\">\n",
    "\n",
    "# 2. Import Dataset\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_data = pd.read_csv('train_data.csv', sep = ',')\n",
    "train_data = pd.read_parquet('transformed_train_data.parquet')\n",
    "test_data = pd.read_parquet('transformed_test_data.parquet')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = load('pipeline.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_original = train_data.copy()\n",
    "test_data_original = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=[\"Claim Injury Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section_3\">\n",
    "\n",
    "# 3. Split and Pipeline\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['Agreement Reached'], axis = 1)\n",
    "y = train_data['Agreement Reached']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split to deal with classe unbalance in the target\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.1,\n",
    "                                                  random_state = 0,\n",
    "                                                  stratify = y,\n",
    "                                                  shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use for feature selection \n",
    "\n",
    "# Target encoding\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "\n",
    "# Apply preprocessing to the training and validation sets\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train,y_train_encoded)\n",
    "X_val_preprocessed = pipeline.transform(X_val)\n",
    "test_data_preprocessed = pipeline.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Attorney/Representative' 'Hearing Held' 'Carrier Type_3A. SELF PUBLIC'\n",
      " 'Time Accident to Assembly' 'Average Weekly Wage Log' 'Assembly Year'\n",
      " 'C-3 Delivered']\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected features:\", X_train_preprocessed.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvsY_MqSoroY"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_4\">\n",
    "\n",
    "# 4. Models\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_train, pred_train , y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9457639152181322\n",
      "Recall: 0.9251781265787502\n",
      "F1 Score: 0.9339566246563661\n",
      "F1 Score Macro: 0.6799950168467361\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96    492515\n",
      "         1.0       0.34      0.57      0.43     24108\n",
      "\n",
      "    accuracy                           0.93    516623\n",
      "   macro avg       0.66      0.76      0.69    516623\n",
      "weighted avg       0.95      0.93      0.94    516623\n",
      "\n",
      "[[465905  26610]\n",
      " [ 10370  13738]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     54724\n",
      "           1       0.32      0.53      0.40      2679\n",
      "\n",
      "    accuracy                           0.93     57403\n",
      "   macro avg       0.65      0.74      0.68     57403\n",
      "weighted avg       0.95      0.93      0.93     57403\n",
      "\n",
      "[[51677  3047]\n",
      " [ 1248  1431]]\n",
      "None\n",
      "Score on training: 0.9284197567665396\n",
      "Score on validation: 0.9251781265787502\n"
     ]
    }
   ],
   "source": [
    "model_xgbc = XGBClassifier(scale_pos_weight = 3.7, subsample = 0.95)\n",
    "\n",
    "# Fit to train data\n",
    "model_xgbc.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Make predictions on validation data\n",
    "\n",
    "labels_train = model_xgbc.predict(X_train_preprocessed)\n",
    "y_pred = model_xgbc.predict(X_val_preprocessed)\n",
    "\n",
    "# Get scores\n",
    "print(\"Precision:\", precision_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score Macro:\", f1_score(y_val_encoded, y_pred, average='macro'))\n",
    "\n",
    "print(metrics(y_train, labels_train, y_val_encoded, y_pred))\n",
    "\n",
    "print(\"Score on training:\" , model_xgbc.score(X_train_preprocessed, y_train_encoded))\n",
    "print(\"Score on validation:\", model_xgbc.score(X_val_preprocessed, y_val_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning - Grid Search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__scale_pos_weight': 3.9, 'model__subsample': 0.95}\n",
      "Best score: 0.42102312896340033\n"
     ]
    }
   ],
   "source": [
    "'''full_pipeline = Pipeline(\n",
    "    pipeline.steps + [('model', XGBClassifier(random_state = random_state))]\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'model__subsample': [0.95, 8.85],  \n",
    "    'model__scale_pos_weight': [3.7, 3.9]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X, y_encoded)\n",
    "\n",
    "# Display best parameters and best cv score \n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__gamma': 1.35, 'model__learning_rate': 0.01, 'model__max_depth': 9, 'model__n_estimators': 2900}\n",
      "Best score: 0.603664268318609\n"
     ]
    }
   ],
   "source": [
    "'''full_pipeline = Pipeline(\n",
    "    pipeline.steps + [('model', XGBClassifier(random_state = random_state, subsample = 0.95, scale_pos_weight = 3.9))]\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': [2800, 2900],  \n",
    "    'model__max_depth': [8,9],\n",
    "    'model__learning_rate': [0.001, 0.01],\n",
    "    'model__gamma':[1,1.35]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X, y_encoded)\n",
    "\n",
    "# Display best parameters and best cv score \n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_) '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Algorithm:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9460405449372886\n",
      "Recall: 0.9256833266554013\n",
      "F1 Score: 0.9343564928738122\n",
      "F1 Score Macro: 0.6816157673210732\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96    492515\n",
      "         1.0       0.35      0.58      0.43     24108\n",
      "\n",
      "    accuracy                           0.93    516623\n",
      "   macro avg       0.66      0.76      0.70    516623\n",
      "weighted avg       0.95      0.93      0.94    516623\n",
      "\n",
      "[[466533  25982]\n",
      " [ 10242  13866]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     54724\n",
      "           1       0.32      0.54      0.40      2679\n",
      "\n",
      "    accuracy                           0.93     57403\n",
      "   macro avg       0.65      0.74      0.68     57403\n",
      "weighted avg       0.95      0.93      0.93     57403\n",
      "\n",
      "[[51698  3026]\n",
      " [ 1240  1439]]\n",
      "None\n",
      "Score on training: 0.929883106249625\n",
      "Score on validation: 0.9256833266554013\n"
     ]
    }
   ],
   "source": [
    "model_xgbc = XGBClassifier(n_estimators=2900, random_state=random_state, learning_rate = 0.01, max_depth = 9, \n",
    "                           gamma = 1.35, scale_pos_weight = 3.9, subsample = 0.95)\n",
    "\n",
    "# Fit to train data\n",
    "model_xgbc.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Make predictions on validation data\n",
    "\n",
    "labels_train = model_xgbc.predict(X_train_preprocessed)\n",
    "y_pred = model_xgbc.predict(X_val_preprocessed)\n",
    "\n",
    "# Get scores\n",
    "print(\"Precision:\", precision_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score Macro:\", f1_score(y_val_encoded, y_pred, average='macro'))\n",
    "\n",
    "print(metrics(y_train, labels_train, y_val_encoded, y_pred))\n",
    "\n",
    "print(\"Score on training:\" , model_xgbc.score(X_train_preprocessed, y_train_encoded))\n",
    "print(\"Score on validation:\", model_xgbc.score(X_val_preprocessed, y_val_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9447088402085785\n",
      "Recall: 0.9329651760360956\n",
      "F1 Score: 0.9382135465267801\n",
      "F1 Score Macro: 0.6829318248560607\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96    492515\n",
      "         1.0       0.35      0.49      0.40     24108\n",
      "\n",
      "    accuracy                           0.93    516623\n",
      "   macro avg       0.66      0.72      0.68    516623\n",
      "weighted avg       0.95      0.93      0.94    516623\n",
      "\n",
      "[[470404  22111]\n",
      " [ 12393  11715]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     54724\n",
      "           1       0.34      0.48      0.40      2679\n",
      "\n",
      "    accuracy                           0.93     57403\n",
      "   macro avg       0.66      0.72      0.68     57403\n",
      "weighted avg       0.94      0.93      0.94     57403\n",
      "\n",
      "[[52265  2459]\n",
      " [ 1389  1290]]\n",
      "None\n",
      "Score on training: 0.9332124198883905\n",
      "Score on validation: 0.9329651760360956\n"
     ]
    }
   ],
   "source": [
    "model_xgbc = XGBClassifier(n_estimators=2900, random_state=random_state, learning_rate = 0.0009, max_depth = 9, \n",
    "                           gamma = 1.35, scale_pos_weight = 3.9, subsample = 0.95)\n",
    "\n",
    "# Fit to train data\n",
    "model_xgbc.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Make predictions on validation data\n",
    "\n",
    "labels_train = model_xgbc.predict(X_train_preprocessed)\n",
    "y_pred = model_xgbc.predict(X_val_preprocessed)\n",
    "\n",
    "# Get scores\n",
    "print(\"Precision:\", precision_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score Macro:\", f1_score(y_val_encoded, y_pred, average='macro'))\n",
    "\n",
    "print(metrics(y_train, labels_train, y_val_encoded, y_pred))\n",
    "\n",
    "print(\"Score on training:\" , model_xgbc.score(X_train_preprocessed, y_train_encoded))\n",
    "print(\"Score on validation:\", model_xgbc.score(X_val_preprocessed, y_val_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final estimators for XGBoost were chosen in a combination of the GridSearchCV and trial-and-error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K Nearest Neighboors Algorithm:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9395047218227405\n",
      "Recall: 0.954427468947616\n",
      "F1 Score: 0.9396184271408513\n",
      "F1 Score Macro: 0.5808025142762964\n",
      "[[54490   234]\n",
      " [ 2382   297]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    492515\n",
      "           1       0.68      0.14      0.23     24108\n",
      "\n",
      "    accuracy                           0.96    516623\n",
      "   macro avg       0.82      0.57      0.60    516623\n",
      "weighted avg       0.95      0.96      0.94    516623\n",
      "\n",
      "[[490921   1594]\n",
      " [ 20740   3368]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     54724\n",
      "           1       0.56      0.11      0.19      2679\n",
      "\n",
      "    accuracy                           0.95     57403\n",
      "   macro avg       0.76      0.55      0.58     57403\n",
      "weighted avg       0.94      0.95      0.94     57403\n",
      "\n",
      "[[54490   234]\n",
      " [ 2382   297]]\n",
      "None\n",
      "Score on training: 0.9567692495301215\n",
      "Score on validation: 0.954427468947616\n"
     ]
    }
   ],
   "source": [
    "\"\"\"modelKNN = KNeighborsClassifier(n_neighbors=13, algorithm=\"kd_tree\")\n",
    "modelKNN.fit(X = X_train_preprocessed, y = y_train_encoded)\n",
    "labels_train = modelKNN.predict(X_train_preprocessed)\n",
    "y_pred = modelKNN.predict(X_val_preprocessed)\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score Macro:\", f1_score(y_val_encoded, y_pred, average='macro'))\n",
    "\n",
    "print(confusion_matrix(y_val_encoded, y_pred))\n",
    "print(metrics(y_train_encoded, labels_train, y_val_encoded, y_pred))\n",
    "\n",
    "print(\"Score on training:\" , modelKNN.score(X_train_preprocessed, y_train_encoded))\n",
    "print(\"Score on validation:\", modelKNN.score(X_val_preprocessed, y_val_encoded))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE oversampling:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"oversample = SMOTE(sampling_strategy=0.2, random_state=42)\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train_preprocessed, y_train_encoded)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9446807420403542\n",
      "Recall: 0.9305611204989286\n",
      "F1 Score: 0.9367905062334977\n",
      "F1 Score Macro: 0.680701738022086\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93    492515\n",
      "           1       0.70      0.55      0.61     98503\n",
      "\n",
      "    accuracy                           0.89    591018\n",
      "   macro avg       0.80      0.75      0.77    591018\n",
      "weighted avg       0.88      0.89      0.88    591018\n",
      "\n",
      "[[468807  23708]\n",
      " [ 44257  54246]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     54724\n",
      "           1       0.33      0.49      0.40      2679\n",
      "\n",
      "    accuracy                           0.93     57403\n",
      "   macro avg       0.65      0.72      0.68     57403\n",
      "weighted avg       0.94      0.93      0.94     57403\n",
      "\n",
      "[[52098  2626]\n",
      " [ 1360  1319]]\n",
      "None\n",
      "Score on training: 0.885003502431398\n",
      "Score on validation: 0.9305611204989286\n"
     ]
    }
   ],
   "source": [
    "\"\"\"model_xgbc = XGBClassifier(n_estimators=2900, random_state=random_state, learning_rate = 0.0009, max_depth = 9, \n",
    "                           gamma = 1.35, subsample = 0.95)\n",
    "\n",
    "# Fit to train data\n",
    "model_xgbc.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on validation data\n",
    "\n",
    "labels_train = model_xgbc.predict(X_train_smote)\n",
    "y_pred = model_xgbc.predict(X_val_preprocessed)\n",
    "\n",
    "# Get scores\n",
    "print(\"Precision:\", precision_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score Macro:\", f1_score(y_val_encoded, y_pred, average='macro'))\n",
    "\n",
    "print(metrics(y_train_smote, labels_train, y_val_encoded, y_pred))\n",
    "\n",
    "print(\"Score on training:\" , model_xgbc.score(X_train_smote, y_train_smote))\n",
    "print(\"Score on validation:\", model_xgbc.score(X_val_preprocessed, y_val_encoded))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oversampled dataset has a very similar F1 macro score when compared to the imbalanced dataset, however, it overfits, and that is why we opted to use the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9456232400254032\n",
      "Recall: 0.9300036583453827\n",
      "F1 Score: 0.9368080200423585\n",
      "F1 Score Macro: 0.684216718673517\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96    492515\n",
      "         1.0       0.34      0.51      0.41     24108\n",
      "\n",
      "    accuracy                           0.93    516623\n",
      "   macro avg       0.66      0.73      0.68    516623\n",
      "weighted avg       0.95      0.93      0.94    516623\n",
      "\n",
      "[[468208  24307]\n",
      " [ 11758  12350]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     54724\n",
      "           1       0.34      0.51      0.41      2679\n",
      "\n",
      "    accuracy                           0.93     57403\n",
      "   macro avg       0.66      0.73      0.68     57403\n",
      "weighted avg       0.95      0.93      0.94     57403\n",
      "\n",
      "[[52014  2710]\n",
      " [ 1308  1371]]\n",
      "None\n",
      "Score on training: 0.9301908741964644\n",
      "Score on validation: 0.9300036583453827\n"
     ]
    }
   ],
   "source": [
    "model_xgbc = XGBClassifier(n_estimators=2900, random_state=random_state, learning_rate = 0.0009, max_depth = 9, \n",
    "                           gamma = 1.35, scale_pos_weight = 3.9, subsample = 0.95)\n",
    "\n",
    "# Fit to train data\n",
    "model_xgbc.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Make predictions on validation data\n",
    "\n",
    "labels_train = model_xgbc.predict(X_train_preprocessed)\n",
    "y_pred = model_xgbc.predict(X_val_preprocessed)\n",
    "\n",
    "# Get scores\n",
    "print(\"Precision:\", precision_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_val_encoded, y_pred, average='weighted'))\n",
    "print(\"F1 Score Macro:\", f1_score(y_val_encoded, y_pred, average='macro'))\n",
    "\n",
    "print(metrics(y_train, labels_train, y_val_encoded, y_pred))\n",
    "\n",
    "print(\"Score on training:\" , model_xgbc.score(X_train_preprocessed, y_train_encoded))\n",
    "print(\"Score on validation:\", model_xgbc.score(X_val_preprocessed, y_val_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assessement of final model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (F1-macro): [0.66375158 0.68438313 0.66129182 0.65716003 0.67542338]\n",
      "Mean CV score: 0.6684019871628759\n"
     ]
    }
   ],
   "source": [
    "full_pipeline = Pipeline(\n",
    "    pipeline.steps + [('model', model_xgbc)]\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Use F1-macro because of class imbalance\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Get scores for cross-validation\n",
    "# Apply preprocessing inside cv for X and y_encoded\n",
    "cv_scores = cross_val_score(full_pipeline, X, y_encoded, cv=cv, scoring=scorer)\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-validation scores (F1-macro):\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final F1 Macro Score: 0.668"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_xgbc.predict(test_data_preprocessed)\n",
    "\n",
    "# Get original y for submission\n",
    "y_pred_categorical = label_encoder.inverse_transform(y_pred) \n",
    "\n",
    "test_data_original.insert(22, \"Agreement Reached\", y_pred_categorical.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_original[\"Agreement Reached\"] = test_data_original[\"Agreement Reached\"].astype('bool')\n",
    "\n",
    "# # Save to CSV in the required format\n",
    "test_data_original.to_parquet(\"test_transformed_agreement.parquet\", index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MqbFmKvxoroF",
    "BL9oVLaT6fER",
    "WVnubShx6mP0",
    "Al0mdDUBoroL",
    "6JjINtuHoroN",
    "akZH_ydMoroO",
    "hcJOdUk1K1kz",
    "6bzFiE2BoroR",
    "XAVSrcx5oroU",
    "TpNi7Q5ioroU",
    "c3wplzqvoroU",
    "wBA2IAMcoroV",
    "FFzpmY9KQPDs",
    "QILO2RwcAxwV",
    "qJDNJDf4BUYd",
    "HMW-CmnSoroX",
    "kkH3JUYYE4VW",
    "ADZcJgYioroX",
    "nZeA99aHGzTQ",
    "z9PEn_R5NjdK"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
