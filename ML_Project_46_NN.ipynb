{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqbFmKvxoroF"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## <center> GROUP PROJECT - TO GRANT OR NOT TO GRANT: DECIDING ON COMPENSATION BENEFITS </center> <br>\n",
    "#  <center> <b> MLP Classifier </center> <br>\n",
    "## <center> Fall Semester 2024-2025 <center>\n",
    "<br>\n",
    "<center> Group 46: <center> <br>\n",
    "<center>Afonso Ascensão, 20240684 <br><center>\n",
    "<center>Duarte Marques, 20240522 <br><center>\n",
    "<center>Joana Esteves, 20240746 <br><center>\n",
    "<center>Rita Serra, 20240515 <br><center>\n",
    "<center>Rodrigo Luís, 20240742 <br><center>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of contents:**\n",
    "- Apply pipeline to preprocess the data.\n",
    "- Implement MLP CLassifier algorithm, perform tuning of hyperparameters making use of gridsearch.\n",
    "- Assessement of the model using cross validation.\n",
    "- Generate prediction for the test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMXFdXdzoroI"
   },
   "source": [
    "**Table of Contents**\n",
    "- [1. Import the needed Libraries](#importlibraries)\n",
    "- [2. Import Dataset](#importdataset)\n",
    "- [3. Preprocessing](#section_3)\n",
    "- [4. MLP Classifier](#section_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL9oVLaT6fER"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_1\">\n",
    "\n",
    "# 1. Import Libraries\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69HiGJ-s8roW",
    "outputId": "80b74294-f5eb-4daa-d490-0fc7f7897f8b"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "## Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import load\n",
    "from transformers import *\n",
    "## Target Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Model algorithm \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "\n",
    "# Cross validation, parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Define a seed\n",
    "random_state = 42\n",
    "\n",
    "# Display all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVnubShx6mP0"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_2\">\n",
    "\n",
    "# 2. Import Dataset and Pipeline\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation w/ split, separate X and y to apply preprocessing\n",
    "transformed_train_split = pd.read_parquet(\"transformed_train_split.parquet\")\n",
    "transformed_val_split = pd.read_parquet(\"transformed_val_split.parquet\")\n",
    "\n",
    "# Test set with predicted agreement column, apply preprocessing \n",
    "test_transformed_agreement = pd.read_parquet(\"test_transformed_agreement.parquet\")\n",
    "\n",
    "# Dataset with no split for cross validation, apply pipeline inside cross validation\n",
    "transformed_train_data = pd.read_parquet(\"transformed_train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline\n",
    "pipeline = load('pipeline.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section_3\">\n",
    "\n",
    "# 3. Preprocessing\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y for train after split\n",
    "X_train = transformed_train_split.drop(['Claim Injury Type'], axis = 1)\n",
    "y_train = transformed_train_split['Claim Injury Type']\n",
    "\n",
    "# Separate X and y for validation after split\n",
    "X_val = transformed_val_split.drop(['Claim Injury Type'], axis = 1)\n",
    "y_val = transformed_val_split['Claim Injury Type']\n",
    "\n",
    "# Separate X and y for dataset before split\n",
    "X = transformed_train_data.drop(['Claim Injury Type'], axis = 1)\n",
    "y = transformed_train_data['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encoding of y for train and validation sets\n",
    "\n",
    "# Initialize target encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode target\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the train, validation and test sets\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train, y_train_encoded)\n",
    "X_val_preprocessed = pipeline.transform(X_val)\n",
    "test_data_preprocessed = pipeline.transform(test_transformed_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Attorney/Representative' 'Average Weekly Wage Log' 'C-2 Delivered'\n",
      " 'Industry Code' 'Time Assembly to Hearing' 'Hearing Held'\n",
      " 'Agreement Reached' 'C-3 Delivered on Time' 'Part of Body Group_Trunk'\n",
      " 'Part of Body Group_Lower Extremities' 'IME-4 Count Log'\n",
      " 'District Name_NYC' 'Part of Body Group_Upper Extremities' 'Gender'\n",
      " 'Carrier Type_2A. SIF' 'Cause of Injury Group_X' 'Assembly Year'\n",
      " 'Cause of Injury Group_VI']\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected features:\", X_train_preprocessed.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section_4\">\n",
    "\n",
    "# 4. MLP Classifier\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables for model:**\n",
    "- X_train_preprocessed;\n",
    "- y_train_preprocessed;\n",
    "- X_val_preprocessed;\n",
    "- y_val_encoded;\n",
    "- test_data_preprocessed.\n",
    "\n",
    "**Variables for CV:**\n",
    "- X: no preprocessing and no split;\n",
    "- y: no preprocessing and no split;\n",
    "- Apply pipeline inside cv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Starting point: 2 hidden layers, width of each hidden layer smaller than the width of the input layer (number of features)\\n# Deafult hyperparameters \\n\\nmlp = MLPClassifier(\\n    hidden_layer_sizes=(16,16),  \\n    random_state=random_state,            \\n)\\n\\nmlp.fit(X_train_preprocessed, y_train_encoded)\\n\\n# Predictions and Evaluation\\ny_pred_train = mlp.predict(X_train_preprocessed)\\ny_pred_val = mlp.predict(X_val_preprocessed)\\n\\nprint(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\\nprint(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val))\\nmlp.fit(X_train_preprocessed, y_train_encoded)\\n\\n# Predictions and Evaluation\\ny_pred_train = mlp.predict(X_train_preprocessed)\\ny_pred_val = mlp.predict(X_val_preprocessed)\\n\\nprint(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\\nprint(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val)) '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Starting point: 2 hidden layers, width of each hidden layer smaller than the width of the input layer (number of features)\n",
    "# Deafult hyperparameters \n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(16,16),  \n",
    "    random_state=random_state,            \n",
    ")\n",
    "\n",
    "mlp.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_train = mlp.predict(X_train_preprocessed)\n",
    "y_pred_val = mlp.predict(X_val_preprocessed)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val))\n",
    "mlp.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_train = mlp.predict(X_train_preprocessed)\n",
    "y_pred_val = mlp.predict(X_val_preprocessed)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val)) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # GridSearchCV\\n\\n# Append the model to the imported pipeline\\nfull_pipeline = Pipeline(\\n    pipeline.steps + [(\\'model\\', MLPClassifier(max_iter=1000, random_state=random_state))]\\n)\\n\\n# Parameter grid\\nparam_grid = {\\n    \\'model__hidden_layer_sizes\\': [(64, 32), (64, 64)], # 2 layers with more neurons than starting point (16,16)\\n    \\'model__alpha\\': [0.001, 0.0001], # deafult 0.0001 vs. 0.001\\n    \\'model__learning_rate_init\\': [0.01, 0.001],  # deafult 0.001 vs. 0.01\\n}\\n\\n# GridSearchCV\\ngrid_search = GridSearchCV(\\n    estimator=full_pipeline,\\n    param_grid=param_grid,\\n    scoring=\\'f1_macro\\',\\n    cv=3,\\n    n_jobs=-1\\n)\\n\\n# Encode target\\nlabel_encoder = LabelEncoder()\\ny_encoded = label_encoder.fit_transform(y)\\n\\n# Fit GridSearchCV\\ngrid_search.fit(X, y_encoded)\\n\\n# Display best parameters and best cv score \\nprint(\"Best parameters:\", grid_search.best_params_)\\nprint(\"Best score:\", grid_search.best_score_) '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # GridSearchCV\n",
    "\n",
    "# Append the model to the imported pipeline\n",
    "full_pipeline = Pipeline(\n",
    "    pipeline.steps + [('model', MLPClassifier(max_iter=1000, random_state=random_state))]\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'model__hidden_layer_sizes': [(64, 32), (64, 64)], # 2 layers with more neurons than starting point (16,16)\n",
    "    'model__alpha': [0.001, 0.0001], # deafult 0.0001 vs. 0.001\n",
    "    'model__learning_rate_init': [0.01, 0.001],  # deafult 0.001 vs. 0.01\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X, y_encoded)\n",
    "\n",
    "# Display best parameters and best cv score \n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Same number of neurons than best solution from gridsearch but with more layers\\n\\nmlp = MLPClassifier(\\n    hidden_layer_sizes=(32,32,32,32),  \\n    activation=\\'relu\\',              \\n    solver=\\'adam\\',                  \\n    learning_rate_init=0.001,      \\n    max_iter=1000,                   \\n    alpha=0.0001,                \\n    random_state=random_state,                \\n)\\n\\nmlp.fit(X_train_preprocessed, y_train_encoded)\\n\\n# Predictions and Evaluation\\ny_pred_train = mlp.predict(X_train_preprocessed)\\ny_pred_val = mlp.predict(X_val_preprocessed)\\n\\nprint(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\\nprint(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val)) '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Same number of neurons than best solution from gridsearch but with more layers\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(32,32,32,32),  \n",
    "    activation='relu',              \n",
    "    solver='adam',                  \n",
    "    learning_rate_init=0.001,      \n",
    "    max_iter=1000,                   \n",
    "    alpha=0.0001,                \n",
    "    random_state=random_state,                \n",
    ")\n",
    "\n",
    "mlp.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_train = mlp.predict(X_train_preprocessed)\n",
    "y_pred_val = mlp.predict(X_val_preprocessed)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val)) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Around the same number of neurons than best solution from gridsearch but with more layers\\nmlp = MLPClassifier(\\n    hidden_layer_sizes=(43,43,43),  \\n    activation=\\'relu\\',              \\n    solver=\\'adam\\',                  \\n    learning_rate_init=0.001,      \\n    max_iter=1000,                   \\n    alpha=0.0001,                \\n    random_state=random_state,                \\n)\\n\\nmlp.fit(X_train_preprocessed, y_train_encoded)\\n\\n# Predictions and Evaluation\\ny_pred_train = mlp.predict(X_train_preprocessed)\\ny_pred_val = mlp.predict(X_val_preprocessed)\\n\\nprint(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\\nprint(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val)) '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Around the same number of neurons than best solution from gridsearch but with more layers\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(43,43,43),  \n",
    "    activation='relu',              \n",
    "    solver='adam',                  \n",
    "    learning_rate_init=0.001,      \n",
    "    max_iter=1000,                   \n",
    "    alpha=0.0001,                \n",
    "    random_state=random_state,                \n",
    ")\n",
    "\n",
    "mlp.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_train = mlp.predict(X_train_preprocessed)\n",
    "y_pred_val = mlp.predict(X_val_preprocessed)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val)) '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model with 2 hidden layers has a better f1 macro score than 3 and 4 hidden layers, and gets predictions for one more class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model with selected hyperparameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanaesteves/.ml_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.38      0.49     11229\n",
      "           1       0.83      0.98      0.90    261970\n",
      "           2       0.48      0.09      0.15     62016\n",
      "           3       0.76      0.81      0.78    133656\n",
      "           4       0.63      0.66      0.64     43452\n",
      "           5       0.45      0.01      0.01      3790\n",
      "           6       0.00      0.00      0.00        87\n",
      "           7       0.55      0.24      0.34       423\n",
      "\n",
      "    accuracy                           0.78    516623\n",
      "   macro avg       0.55      0.40      0.41    516623\n",
      "weighted avg       0.74      0.78      0.74    516623\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.39      0.50      1248\n",
      "           1       0.83      0.98      0.89     29108\n",
      "           2       0.43      0.08      0.13      6890\n",
      "           3       0.75      0.80      0.78     14851\n",
      "           4       0.62      0.66      0.64      4828\n",
      "           5       0.33      0.01      0.02       421\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.56      0.19      0.29        47\n",
      "\n",
      "    accuracy                           0.78     57403\n",
      "   macro avg       0.53      0.39      0.41     57403\n",
      "weighted avg       0.73      0.78      0.74     57403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanaesteves/.ml_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/joanaesteves/.ml_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/joanaesteves/.ml_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/joanaesteves/.ml_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/joanaesteves/.ml_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64,64),    # 2 hidden layers W/ 64 neurons each\n",
    "    activation='relu',             # ReLU activation function - default\n",
    "    solver='adam',                 # Adam solver - deafult\n",
    "    learning_rate_init=0.001,      # Initial learning rate for Adam \n",
    "    max_iter=1000,                 # Maximum number of iterations\n",
    "    alpha=0.0001,                 # L2 regularization to prevent overfitting \n",
    "    random_state=random_state,     \n",
    ")\n",
    "\n",
    "mlp.fit(X_train_preprocessed, y_train_encoded)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred_train = mlp.predict(X_train_preprocessed)\n",
    "y_pred_val = mlp.predict(X_val_preprocessed)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train_encoded, y_pred_train))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val_encoded, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The scores are similar for train and validation.\n",
    "- The model is not predicting class 6, most likely because it does not have enough observations.\n",
    "- The minority classes have a very low f1 score.\n",
    "- The f1 macro scores are low for both train and validation which indicate the model may be underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation w/ 5 splits for final assessement of the model with selected hyperparameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (F1-macro): [0.39539424 0.40278262 0.38386223 0.41036415 0.38424573]\n",
      "Mean CV score: 0.3953297931932184\n"
     ]
    }
   ],
   "source": [
    "# Append the model to the imported pipeline\n",
    "full_pipeline = Pipeline(\n",
    "    pipeline.steps + [('model', mlp)]\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Use F1-macro because of class imbalance\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Get scores for cross-validation\n",
    "# Apply preprocessing inside cv for X and y_encoded\n",
    "cv_scores = cross_val_score(full_pipeline, X, y_encoded, cv=cv, scoring=scorer)\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-validation scores (F1-macro):\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean CV f1 macro: 0.3953297931932184\n",
    "- This value will be compared with the other models mean cv scores to select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions for test set using all incial train data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Fit pipeline on X and apply tranformations\n",
    "X_preprocessed = pipeline.fit_transform(X, y_encoded)\n",
    "\n",
    "# Apply pipeline fitted on X\n",
    "test_data_preprocessed_X = pipeline.transform(test_transformed_agreement)\n",
    "\n",
    "# Fit on X \n",
    "mlp.fit(X_preprocessed,y_encoded)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = mlp.predict(test_data_preprocessed_X)\n",
    "\n",
    "# Get original y for submission\n",
    "y_pred_categorical = label_encoder.inverse_transform(y_pred) \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Claim Identifier\": test_data_preprocessed.index,\n",
    "    \"Claim Injury Type\": y_pred_categorical\n",
    "})\n",
    "\n",
    "\n",
    "# Save to CSV to upload on kaggle\n",
    "submission.to_csv(\"Group46_versionX.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kaggle f1 macro score from test: 0.35491."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MqbFmKvxoroF",
    "BL9oVLaT6fER",
    "WVnubShx6mP0",
    "Al0mdDUBoroL",
    "6JjINtuHoroN",
    "akZH_ydMoroO",
    "hcJOdUk1K1kz",
    "6bzFiE2BoroR",
    "XAVSrcx5oroU",
    "TpNi7Q5ioroU",
    "c3wplzqvoroU",
    "wBA2IAMcoroV",
    "FFzpmY9KQPDs",
    "QILO2RwcAxwV",
    "qJDNJDf4BUYd",
    "HMW-CmnSoroX",
    "kkH3JUYYE4VW",
    "ADZcJgYioroX",
    "nZeA99aHGzTQ",
    "z9PEn_R5NjdK"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
